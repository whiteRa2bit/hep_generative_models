{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import wandb\n",
    "import tqdm\n",
    "\n",
    "from generation.config import WANDB_PROJECT, SIGNALS_TRAINING_CONFIG as config\n",
    "from generation.dataset.signals_dataset import SignalsDataset\n",
    "from generation.nets.signals import Generator, Discriminator\n",
    "from generation.training.wgan_trainer import WganTrainer\n",
    "from generation.utils import set_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['device'] = 'cuda:0'\n",
    "config['lr'] = 3e-4\n",
    "config['x_dim'] = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = SignalsDataset(signal_dim=config['x_dim'])\n",
    "dataloader = DataLoader(dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "generator = Generator(config).to(config['device'])\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: whitera2bit (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.7 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.10.2\n",
      "wandb: Run data is saved locally in wandb/run-20201021_185006-2j0cnm37\n",
      "wandb: Syncing run upbeat-waterfall-293\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/whitera2bit/hep_generative_models\" target=\"_blank\">https://wandb.ai/whitera2bit/hep_generative_models</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/whitera2bit/hep_generative_models/runs/2j0cnm37\" target=\"_blank\">https://wandb.ai/whitera2bit/hep_generative_models/runs/2j0cnm37</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f76c3603e10>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(config=config, project=WANDB_PROJECT)\n",
    "wandb.watch(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1466/5000 [1:11:12<2:50:25,  2.89s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm.tqdm(range(config['epochs_num'])):\n",
    "    for it, data in enumerate(dataloader):\n",
    "        X = Variable(data)\n",
    "        X = X.to(config['device'])\n",
    "        z = Variable(torch.randn(X.shape[0], config['z_dim']))\n",
    "        z = z.to(config['device'])\n",
    "\n",
    "        g_sample = generator(z)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(X, g_sample)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % config['log_each'] == 0:\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"MSE loss\": loss.cpu(),\n",
    "            },\n",
    "            step=epoch)\n",
    "        generator.visualize(g_sample, X, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
